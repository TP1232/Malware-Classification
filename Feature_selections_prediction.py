import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import time
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_selection import SelectFromModel



# Number of Features to be select
n_features =10

df = pd.read_csv("/archive/Dataset/Dataset/train/LargeTrain.csv")

X = df.iloc[:,:-1]

Y = df.iloc[:,-1]


# Fit the estimator; forest is the instance of DecisionTreeClassifier


#using the best tune value from decision Tree tuning
model = DecisionTreeClassifier(max_depth=10,criterion='gini',splitter='best',min_weight_fraction_leaf=0.0)

# Feature Selection 
sfm = SelectFromModel(model, max_features=n_features,threshold=-np.inf)


# Transform the training data set

sfm.fit(X,Y)
sfm.get_support()
# Array of selected features
selection = sfm.get_support(indices=True)
#  Selecting features from the dataset 
data = df.iloc[:,selection]

# Normalization
scaler = MinMaxScaler()
scaler.fit(data)
normalized_x = scaler.transform(data)
normalized_y = Y

X_train, X_test, Y_train, Y_test = train_test_split(normalized_x, normalized_y, random_state=10, test_size=0.2)

# Decision Tree model for seleted features 
DT = DecisionTreeClassifier(max_depth=10,criterion='gini',splitter='best',min_weight_fraction_leaf=0.0)
print('-'*35,'DT','-'*35)
start = time.time()
print('program start...')
print()

DT.fit(X_train, Y_train)
print()

print('prediction:')
y_pred = DT.predict(X_test)
print(y_pred)
print()

print('Score:')
score = DT.score(X_test,Y_test)
print(score)

end = time.time()
print('program end...')
print()
print('time cost: ')
print(end - start, 'seconds')

print("Classifiction Report :")
print(classification_report(Y_test, y_pred))
print('#'*70)


# =============================================================================
# =============================================================================
# # Reasults for diffrent n_value for feature selection
# =============================================================================
# =============================================================================
# selection_10 = [ 199,  276,  306,  320,  468, 1330, 1422, 1493, 1497, 1684]
# selection_25 = [  30,  107,  117,  131,  199,  255,  264,  276,  284,  288,  303,
#         306,  314,  468,  587, 1219, 1330, 1422, 1453, 1454, 1493, 1497,
#        1521, 1684, 1718]
# selection_50 =[  22,   30,   47,   56,   59,   85,   87,   90,  107,  117,  118,
#         131,  151,  172,  199,  255,  264,  273,  276,  281,  284,  288,
#         289,  290,  295,  306,  314,  320,  465,  468,  517,  776,  947,
#        1219, 1298, 1330, 1378, 1395, 1422, 1439, 1453, 1493, 1497, 1517,
#        1520, 1521, 1545, 1684, 1726, 1758]
# selection_75 = [   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   22,
#          31,   81,   85,   99,  102,  107,  108,  114,  121,  131,  172,
#         175,  199,  208,  254,  255,  268,  274,  276,  278,  284,  288,
#         290,  303,  306,  314,  465,  468,  596,  680,  695, 1016, 1139,
#        1162, 1219, 1269, 1282, 1285, 1298, 1318, 1330, 1372, 1392, 1422,
#        1427, 1439, 1445, 1453, 1459, 1460, 1471, 1493, 1497, 1498, 1519,
#        1520, 1521, 1684, 1714, 1716, 1745, 1757, 1780, 1790]

# selection_100 = [   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,
#          11,   12,   13,   14,   15,   16,   17,   18,   19,   20,   21,
#          22,   23,   24,   25,   26,   27,   28,   29,   30,   31,   32,
#          33,   34,   35,   36,   37,   38,   39,   40,   41,   66,   73,
#          85,  103,  107,  108,  117,  128,  131,  172,  199,  224,  231,
#         255,  263,  264,  269,  276,  284,  288,  289,  290,  303,  306,
#         312,  314,  319,  465,  468,  469,  517,  543,  677, 1153, 1219,
#        1241, 1286, 1290, 1302, 1330, 1382, 1422, 1453, 1461, 1464, 1493,
#        1497, 1500, 1502, 1517, 1520, 1521, 1577, 1665, 1681, 1684, 1696,
#        1698]